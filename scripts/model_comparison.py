"""
Model Comparison Script - Find the Best ML Model for Crime Prediction
Run this to test multiple models and see which performs best on YOUR data.

Usage:
    python scripts/model_comparison.py
"""

import pandas as pd
import numpy as np
from pathlib import Path
import sys
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_absolute_error, r2_score
from sklearn.preprocessing import LabelEncoder
import warnings
warnings.filterwarnings('ignore')

# Add project root to path
project_root = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(project_root))

# Import data loader
from src.data_loader import load_crime_data, process_datetime_columns

print("=" * 80)
print("ğŸ”¬ CRIME PREDICTION MODEL COMPARISON")
print("=" * 80)

# Load data
print("\nğŸ“Š Loading data...")
df = load_crime_data()
df = process_datetime_columns(df)
print(f"âœ… Loaded {len(df):,} incidents")

# Prepare data
print("\nğŸ”§ Preparing features...")
ml_data = df.dropna(subset=["hour", "weekday", "neighborhood"]).copy()
crime_counts = ml_data.groupby(["hour", "weekday", "neighborhood"]).size().reset_index(name="incident_count")

# Encode features
le_weekday = LabelEncoder()
le_neighborhood = LabelEncoder()
crime_counts["weekday_encoded"] = le_weekday.fit_transform(crime_counts["weekday"])
crime_counts["neighborhood_encoded"] = le_neighborhood.fit_transform(crime_counts["neighborhood"])
crime_counts["is_night"] = ((crime_counts["hour"] >= 20) | (crime_counts["hour"] <= 5)).astype(int)
crime_counts["is_evening"] = ((crime_counts["hour"] >= 18) & (crime_counts["hour"] < 22)).astype(int)
crime_counts["is_weekend"] = crime_counts["weekday"].isin(["Saturday", "Sunday"]).astype(int)
crime_counts["is_rush_hour"] = crime_counts["hour"].isin([7, 8, 9, 17, 18, 19]).astype(int)

print(f"âœ… Created {len(crime_counts)} time-location scenarios")

# ============================================================================
# TEST 1: CLASSIFICATION MODELS (Predict Risk Level: High/Medium/Low)
# ============================================================================

print("\n" + "=" * 80)
print("TEST 1: CLASSIFICATION MODELS (Risk Level Prediction)")
print("=" * 80)

# Create risk categories
crime_counts["risk"] = pd.cut(
    crime_counts["incident_count"],
    bins=[0, crime_counts["incident_count"].quantile(0.60), 
          crime_counts["incident_count"].quantile(0.85), 
          crime_counts["incident_count"].max()],
    labels=["Low", "Medium", "High"]
)

X_class = crime_counts[["hour", "weekday_encoded", "neighborhood_encoded", 
                         "is_night", "is_evening", "is_weekend", "is_rush_hour"]]
y_class = crime_counts["risk"]

X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_class, y_class, test_size=0.25, random_state=42, stratify=y_class)

classification_models = {
    "Random Forest": None,
    "Gradient Boosting": None,
    "XGBoost": None,
    "LightGBM": None,
    "Logistic Regression": None,
    "SVM": None,
    "Decision Tree": None,
    "KNN": None
}

classification_results = []

# Random Forest
try:
    from sklearn.ensemble import RandomForestClassifier
    model = RandomForestClassifier(n_estimators=100, max_depth=8, random_state=42, n_jobs=-1)
    model.fit(X_train_c, y_train_c)
    y_pred = model.predict(X_test_c)
    classification_results.append({
        "Model": "Random Forest",
        "Train Acc": f"{model.score(X_train_c, y_train_c):.3f}",
        "Test Acc": f"{accuracy_score(y_test_c, y_pred):.3f}",
        "Precision": f"{precision_score(y_test_c, y_pred, average='weighted'):.3f}",
        "Recall": f"{recall_score(y_test_c, y_pred, average='weighted'):.3f}",
        "F1": f"{f1_score(y_test_c, y_pred, average='weighted'):.3f}"
    })
    print("âœ… Random Forest")
except Exception as e:
    print(f"âŒ Random Forest: {e}")

# Gradient Boosting
try:
    from sklearn.ensemble import GradientBoostingClassifier
    model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=42)
    model.fit(X_train_c, y_train_c)
    y_pred = model.predict(X_test_c)
    classification_results.append({
        "Model": "Gradient Boosting",
        "Train Acc": f"{model.score(X_train_c, y_train_c):.3f}",
        "Test Acc": f"{accuracy_score(y_test_c, y_pred):.3f}",
        "Precision": f"{precision_score(y_test_c, y_pred, average='weighted'):.3f}",
        "Recall": f"{recall_score(y_test_c, y_pred, average='weighted'):.3f}",
        "F1": f"{f1_score(y_test_c, y_pred, average='weighted'):.3f}"
    })
    print("âœ… Gradient Boosting")
except Exception as e:
    print(f"âŒ Gradient Boosting: {e}")

# XGBoost
try:
    from xgboost import XGBClassifier
    model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=42, eval_metric='mlogloss')
    model.fit(X_train_c, y_train_c)
    y_pred = model.predict(X_test_c)
    classification_results.append({
        "Model": "XGBoost",
        "Train Acc": f"{model.score(X_train_c, y_train_c):.3f}",
        "Test Acc": f"{accuracy_score(y_test_c, y_pred):.3f}",
        "Precision": f"{precision_score(y_test_c, y_pred, average='weighted'):.3f}",
        "Recall": f"{recall_score(y_test_c, y_pred, average='weighted'):.3f}",
        "F1": f"{f1_score(y_test_c, y_pred, average='weighted'):.3f}"
    })
    print("âœ… XGBoost")
except Exception as e:
    print(f"âš ï¸  XGBoost not installed (pip install xgboost)")

# LightGBM
try:
    from lightgbm import LGBMClassifier
    model = LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=42, verbose=-1)
    model.fit(X_train_c, y_train_c)
    y_pred = model.predict(X_test_c)
    classification_results.append({
        "Model": "LightGBM",
        "Train Acc": f"{model.score(X_train_c, y_train_c):.3f}",
        "Test Acc": f"{accuracy_score(y_test_c, y_pred):.3f}",
        "Precision": f"{precision_score(y_test_c, y_pred, average='weighted'):.3f}",
        "Recall": f"{recall_score(y_test_c, y_pred, average='weighted'):.3f}",
        "F1": f"{f1_score(y_test_c, y_pred, average='weighted'):.3f}"
    })
    print("âœ… LightGBM")
except Exception as e:
    print(f"âš ï¸  LightGBM not installed (pip install lightgbm)")

# Logistic Regression
try:
    from sklearn.linear_model import LogisticRegression
    model = LogisticRegression(max_iter=1000, random_state=42)
    model.fit(X_train_c, y_train_c)
    y_pred = model.predict(X_test_c)
    classification_results.append({
        "Model": "Logistic Regression",
        "Train Acc": f"{model.score(X_train_c, y_train_c):.3f}",
        "Test Acc": f"{accuracy_score(y_test_c, y_pred):.3f}",
        "Precision": f"{precision_score(y_test_c, y_pred, average='weighted'):.3f}",
        "Recall": f"{recall_score(y_test_c, y_pred, average='weighted'):.3f}",
        "F1": f"{f1_score(y_test_c, y_pred, average='weighted'):.3f}"
    })
    print("âœ… Logistic Regression")
except Exception as e:
    print(f"âŒ Logistic Regression: {e}")

# Decision Tree
try:
    from sklearn.tree import DecisionTreeClassifier
    model = DecisionTreeClassifier(max_depth=8, random_state=42)
    model.fit(X_train_c, y_train_c)
    y_pred = model.predict(X_test_c)
    classification_results.append({
        "Model": "Decision Tree",
        "Train Acc": f"{model.score(X_train_c, y_train_c):.3f}",
        "Test Acc": f"{accuracy_score(y_test_c, y_pred):.3f}",
        "Precision": f"{precision_score(y_test_c, y_pred, average='weighted'):.3f}",
        "Recall": f"{recall_score(y_test_c, y_pred, average='weighted'):.3f}",
        "F1": f"{f1_score(y_test_c, y_pred, average='weighted'):.3f}"
    })
    print("âœ… Decision Tree")
except Exception as e:
    print(f"âŒ Decision Tree: {e}")

# Display Classification Results
print("\nğŸ“Š CLASSIFICATION RESULTS:")
print("-" * 100)
results_df = pd.DataFrame(classification_results)
print(results_df.to_string(index=False))

# Find best model
best_idx = results_df['Test Acc'].astype(float).idxmax()
best_model = results_df.iloc[best_idx]['Model']
print(f"\nğŸ† BEST CLASSIFICATION MODEL: {best_model} (Test Acc: {results_df.iloc[best_idx]['Test Acc']})")

# ============================================================================
# TEST 2: REGRESSION MODELS (Predict Actual Crime Count)
# ============================================================================

print("\n" + "=" * 80)
print("TEST 2: REGRESSION MODELS (Crime Count Prediction)")
print("=" * 80)

X_reg = crime_counts[["hour", "weekday_encoded", "neighborhood_encoded", 
                       "is_night", "is_evening", "is_weekend", "is_rush_hour"]]
y_reg = crime_counts["incident_count"]

X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_reg, y_reg, test_size=0.25, random_state=42)

regression_results = []

# Random Forest Regressor
try:
    from sklearn.ensemble import RandomForestRegressor
    model = RandomForestRegressor(n_estimators=100, max_depth=8, random_state=42, n_jobs=-1)
    model.fit(X_train_r, y_train_r)
    y_pred = model.predict(X_test_r)
    regression_results.append({
        "Model": "Random Forest",
        "Train RÂ²": f"{model.score(X_train_r, y_train_r):.3f}",
        "Test RÂ²": f"{r2_score(y_test_r, y_pred):.3f}",
        "MAE": f"{mean_absolute_error(y_test_r, y_pred):.2f}",
        "RMSE": f"{np.sqrt(np.mean((y_test_r - y_pred)**2)):.2f}"
    })
    print("âœ… Random Forest Regressor")
except Exception as e:
    print(f"âŒ Random Forest: {e}")

# Gradient Boosting Regressor
try:
    from sklearn.ensemble import GradientBoostingRegressor
    model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=42)
    model.fit(X_train_r, y_train_r)
    y_pred = model.predict(X_test_r)
    regression_results.append({
        "Model": "Gradient Boosting",
        "Train RÂ²": f"{model.score(X_train_r, y_train_r):.3f}",
        "Test RÂ²": f"{r2_score(y_test_r, y_pred):.3f}",
        "MAE": f"{mean_absolute_error(y_test_r, y_pred):.2f}",
        "RMSE": f"{np.sqrt(np.mean((y_test_r - y_pred)**2)):.2f}"
    })
    print("âœ… Gradient Boosting Regressor")
except Exception as e:
    print(f"âŒ Gradient Boosting: {e}")

# XGBoost Regressor
try:
    from xgboost import XGBRegressor
    model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=42)
    model.fit(X_train_r, y_train_r)
    y_pred = model.predict(X_test_r)
    regression_results.append({
        "Model": "XGBoost",
        "Train RÂ²": f"{model.score(X_train_r, y_train_r):.3f}",
        "Test RÂ²": f"{r2_score(y_test_r, y_pred):.3f}",
        "MAE": f"{mean_absolute_error(y_test_r, y_pred):.2f}",
        "RMSE": f"{np.sqrt(np.mean((y_test_r - y_pred)**2)):.2f}"
    })
    print("âœ… XGBoost Regressor")
except Exception as e:
    print(f"âš ï¸  XGBoost not installed")

# LightGBM Regressor
try:
    from lightgbm import LGBMRegressor
    model = LGBMRegressor(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=42, verbose=-1)
    model.fit(X_train_r, y_train_r)
    y_pred = model.predict(X_test_r)
    regression_results.append({
        "Model": "LightGBM",
        "Train RÂ²": f"{model.score(X_train_r, y_train_r):.3f}",
        "Test RÂ²": f"{r2_score(y_test_r, y_pred):.3f}",
        "MAE": f"{mean_absolute_error(y_test_r, y_pred):.2f}",
        "RMSE": f"{np.sqrt(np.mean((y_test_r - y_pred)**2)):.2f}"
    })
    print("âœ… LightGBM Regressor")
except Exception as e:
    print(f"âš ï¸  LightGBM not installed")

# Linear Regression
try:
    from sklearn.linear_model import LinearRegression
    model = LinearRegression()
    model.fit(X_train_r, y_train_r)
    y_pred = model.predict(X_test_r)
    regression_results.append({
        "Model": "Linear Regression",
        "Train RÂ²": f"{model.score(X_train_r, y_train_r):.3f}",
        "Test RÂ²": f"{r2_score(y_test_r, y_pred):.3f}",
        "MAE": f"{mean_absolute_error(y_test_r, y_pred):.2f}",
        "RMSE": f"{np.sqrt(np.mean((y_test_r - y_pred)**2)):.2f}"
    })
    print("âœ… Linear Regression")
except Exception as e:
    print(f"âŒ Linear Regression: {e}")

# Decision Tree Regressor
try:
    from sklearn.tree import DecisionTreeRegressor
    model = DecisionTreeRegressor(max_depth=8, random_state=42)
    model.fit(X_train_r, y_train_r)
    y_pred = model.predict(X_test_r)
    regression_results.append({
        "Model": "Decision Tree",
        "Train RÂ²": f"{model.score(X_train_r, y_train_r):.3f}",
        "Test RÂ²": f"{r2_score(y_test_r, y_pred):.3f}",
        "MAE": f"{mean_absolute_error(y_test_r, y_pred):.2f}",
        "RMSE": f"{np.sqrt(np.mean((y_test_r - y_pred)**2)):.2f}"
    })
    print("âœ… Decision Tree Regressor")
except Exception as e:
    print(f"âŒ Decision Tree: {e}")

# Display Regression Results
print("\nğŸ“Š REGRESSION RESULTS:")
print("-" * 100)
results_df_reg = pd.DataFrame(regression_results)
print(results_df_reg.to_string(index=False))

# Find best model
best_idx_reg = results_df_reg['Test RÂ²'].astype(float).idxmax()
best_model_reg = results_df_reg.iloc[best_idx_reg]['Model']
print(f"\nğŸ† BEST REGRESSION MODEL: {best_model_reg} (Test RÂ²: {results_df_reg.iloc[best_idx_reg]['Test RÂ²']}, MAE: {results_df_reg.iloc[best_idx_reg]['MAE']})")

# ============================================================================
# FINAL RECOMMENDATIONS
# ============================================================================

print("\n" + "=" * 80)
print("ğŸ“‹ FINAL RECOMMENDATIONS")
print("=" * 80)

print(f"""
ğŸ¯ FOR RISK CLASSIFICATION (High/Medium/Low):
   Best Model: {best_model}
   Test Accuracy: {results_df.iloc[best_idx]['Test Acc']}
   F1 Score: {results_df.iloc[best_idx]['F1']}
   
   âœ… Use this for: Dashboard risk warnings, color-coded maps
   
ğŸ¯ FOR CRIME COUNT PREDICTION (Actual Numbers):
   Best Model: {best_model_reg}
   Test RÂ² Score: {results_df_reg.iloc[best_idx_reg]['Test RÂ²']}
   MAE: {results_df_reg.iloc[best_idx_reg]['MAE']} crimes
   
   âœ… Use this for: Resource allocation, staffing predictions
   
ğŸ’¡ RECOMMENDATION:
   - Implement BOTH models in your dashboard
   - Use classification for quick risk assessments
   - Use regression for detailed planning
   - Current models are {'OPTIMAL' if best_model == 'Gradient Boosting' and best_model_reg == 'Gradient Boosting' else 'GOOD but could be better'}
""")

print("\nâœ… Model comparison complete!")
print("=" * 80)